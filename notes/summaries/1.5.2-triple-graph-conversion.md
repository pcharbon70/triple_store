# Task 1.5.2: Triple/Graph Conversion - Summary

## Overview

Extended the RDF.ex Adapter layer to support conversion of composite structures: triples and graphs.

## Files Modified

### `lib/triple_store/adapter.ex` (Extended)

Added new types and functions for triple/graph conversion:

**New Types:**
| Type | Description |
|------|-------------|
| `rdf_triple` | RDF triple as `{subject, predicate, object}` tuple |
| `internal_triple` | Internal triple as `{s_id, p_id, o_id}` tuple |

**Triple Conversion Functions:**
| Function | Description |
|----------|-------------|
| `from_rdf_triple/2` | Converts RDF triple to internal `{s_id, p_id, o_id}` |
| `to_rdf_triple/2` | Converts internal triple back to RDF |
| `from_rdf_triples/2` | Batch conversion (efficient term batching) |
| `to_rdf_triples/2` | Batch reverse conversion |

**Graph Conversion Functions:**
| Function | Description |
|----------|-------------|
| `from_rdf_graph/2` | Converts RDF.Graph to list of internal triples |
| `to_rdf_graph/3` | Converts internal triples to RDF.Graph with options |
| `stream_from_rdf_graph/2` | Lazy stream conversion for large graphs |

### `test/triple_store/adapter/triple_graph_conversion_test.exs` (35 tests)

Comprehensive test coverage including:
- Single and batch triple conversion
- Graph conversion with various term types
- Roundtrip tests preserving values
- Edge cases (unicode, large graphs, mixed inline/dictionary literals)
- Error handling for missing IDs

## Implementation Details

### Triple Conversion

```elixir
# Single triple conversion
def from_rdf_triple(manager, {subject, predicate, object}) do
  with {:ok, s_id} <- term_to_id(manager, subject),
       {:ok, p_id} <- term_to_id(manager, predicate),
       {:ok, o_id} <- term_to_id(manager, object) do
    {:ok, {s_id, p_id, o_id}}
  end
end

# Efficient batch conversion (all terms at once)
def from_rdf_triples(manager, triples) do
  all_terms = Enum.flat_map(triples, fn {s, p, o} -> [s, p, o] end)
  case terms_to_ids(manager, all_terms) do
    {:ok, all_ids} ->
      internal_triples =
        all_ids
        |> Enum.chunk_every(3)
        |> Enum.map(fn [s, p, o] -> {s, p, o} end)
      {:ok, internal_triples}
    error -> error
  end
end
```

### Graph Conversion

```elixir
# Graph to internal triples
def from_rdf_graph(manager, %RDF.Graph{} = graph) do
  triples = RDF.Graph.triples(graph)
  from_rdf_triples(manager, triples)
end

# Internal triples to graph with options
def to_rdf_graph(db, triples, opts \\ []) do
  case to_rdf_triples(db, triples) do
    {:ok, rdf_triples} ->
      valid_triples = Enum.filter(rdf_triples, &is_tuple/1)
      {:ok, RDF.Graph.new(valid_triples, opts)}
    error -> error
  end
end

# Lazy stream for large graphs
def stream_from_rdf_graph(manager, %RDF.Graph{} = graph) do
  graph
  |> RDF.Graph.triples()
  |> Stream.map(fn triple -> from_rdf_triple(manager, triple) end)
end
```

## Performance Considerations

| Approach | Use Case |
|----------|----------|
| `from_rdf_triple/2` | Single triple conversion |
| `from_rdf_triples/2` | Batch - efficient term batching |
| `from_rdf_graph/2` | Full graph conversion |
| `stream_from_rdf_graph/2` | Very large graphs - lazy evaluation |

The batch functions (`from_rdf_triples/2`, `to_rdf_triples/2`) collect all terms and process them together, which is more efficient than individual conversions when handling multiple triples.

## Error Handling

| Return | Meaning |
|--------|---------|
| `{:ok, result}` | Successful conversion |
| `:not_found` | ID not in dictionary (reverse lookup) |
| `{:error, reason}` | Validation or allocation failure |

For batch operations:
- `from_rdf_triples/2` returns early on first error
- `to_rdf_triples/2` returns `:not_found` for missing individual triples
- `to_rdf_graph/3` filters out `:not_found` entries from resulting graph

## Test Results

- **35 new tests** for triple/graph conversion
- **688 total tests** (up from 653)
- **All tests passing**

## Next Task

Task 1.5.3: Bulk Loading Pipeline - Implement efficient bulk loading using Flow for parallel processing with batched writes.
