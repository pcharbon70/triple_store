# Task 1.6.1: Triple Counts - Summary

## Overview

Implemented basic statistics functions for the triple store, providing counts and cardinality estimates used by the query optimizer.

## Files Created

### `lib/triple_store/statistics.ex` (~250 lines)

New module providing statistics collection:

| Function | Description | Index Used |
|----------|-------------|------------|
| `triple_count/1` | Total number of triples | SPO (via Index.count) |
| `predicate_count/2` | Count for specific predicate | POS (via Index.count) |
| `distinct_subjects/1` | Count of unique subjects | SPO full scan |
| `distinct_predicates/1` | Count of unique predicates | POS full scan |
| `distinct_objects/1` | Count of unique objects | OSP full scan |
| `all/1` | All statistics in one call | All indices |

### `test/triple_store/statistics_test.exs` (20 tests)

Comprehensive test coverage including:
- Empty store cases
- Single value cases
- Multiple value cases
- Edge cases (large IDs, many triples)
- All statistics function

## Implementation Details

### Triple Counts

```elixir
# Total triple count
{:ok, count} = Statistics.triple_count(db)

# Per-predicate count
{:ok, count} = Statistics.predicate_count(db, predicate_id)
```

Uses `Index.count/2` which performs a prefix scan on the appropriate index.

### Distinct Counts

```elixir
# Get distinct counts
{:ok, subjects} = Statistics.distinct_subjects(db)
{:ok, predicates} = Statistics.distinct_predicates(db)
{:ok, objects} = Statistics.distinct_objects(db)

# Or get all at once
{:ok, stats} = Statistics.all(db)
# => %{triple_count: 1000, distinct_subjects: 300,
#      distinct_predicates: 15, distinct_objects: 500}
```

Implementation uses `Stream.dedup()` on sorted index keys:
- SPO index for distinct subjects (first 8 bytes)
- POS index for distinct predicates (first 8 bytes)
- OSP index for distinct objects (first 8 bytes)

### Performance Characteristics

| Function | Complexity | Notes |
|----------|------------|-------|
| `triple_count/1` | O(n) | Full SPO scan |
| `predicate_count/2` | O(m) | POS prefix scan, m = triples with predicate |
| `distinct_subjects/1` | O(n) | Full SPO scan with dedup |
| `distinct_predicates/1` | O(n) | Full POS scan with dedup |
| `distinct_objects/1` | O(n) | Full OSP scan with dedup |

For large datasets, these functions should be cached. The Statistics Cache (Task 1.6.2) will provide a GenServer for this purpose.

## Architecture

```
┌─────────────────────────────────────────────────────────────┐
│                    Statistics Module                         │
│  triple_count, predicate_count, distinct_*                  │
├─────────────────────────────────────────────────────────────┤
│                    Index Module                              │
│              count/2, lookup/2                               │
├─────────────────────────────────────────────────────────────┤
│                    NIF Layer                                 │
│         prefix_stream, prefix_iterator                       │
├─────────────────────────────────────────────────────────────┤
│              RocksDB Column Families                         │
│                 SPO, POS, OSP                                │
└─────────────────────────────────────────────────────────────┘
```

## Test Results

- **20 new tests** for statistics functions
- **761 total tests** (up from 741)
- **All tests passing**

## Usage for Query Optimization

These statistics will be used by the SPARQL query optimizer (Phase 2) to:

1. **Estimate result sizes**: `triple_count` and `predicate_count` estimate BGP result cardinality
2. **Select join order**: Put most selective patterns first based on predicate counts
3. **Choose index**: Use distinct counts to decide between index scan vs hash join

## Next Task

Task 1.6.2: Statistics Cache - GenServer for cached stats with periodic refresh and invalidation on bulk updates.
