defmodule TripleStore.OperationalTestingTest do
  @moduledoc """
  Operational testing for Task 5.7.3.

  These tests validate production operational features including:
  - Backup/restore cycle data preservation
  - Telemetry integration with Prometheus
  - Health checks under various conditions
  - Graceful shutdown and restart

  These are integration tests that verify the complete operational
  workflow works correctly in realistic scenarios.

  ## Timeout Configuration

  Default timeout: 120 seconds (2 minutes)
  Rationale: Operational tests involve backup/restore cycles and multiple
  store open/close operations which can be slow on CI systems.
  """

  use ExUnit.Case, async: false

  import TripleStore.Test.IntegrationHelpers,
    only: [
      create_test_store: 1,
      cleanup_test_store: 2,
      cleanup_test_path: 1,
      open_with_retry: 1,
      wait_for_lock_release: 0,
      load_test_data: 2,
      get_triple_count: 1,
      ensure_prometheus_started: 0
    ]

  alias TripleStore.Backup
  alias TripleStore.Health
  alias TripleStore.Metrics
  alias TripleStore.Prometheus

  @moduletag :integration
  # 2 minute timeout for operational tests (backup/restore, multiple open/close cycles)
  @moduletag timeout: 120_000

  # ===========================================================================
  # 5.7.3.1: Backup/Restore Cycle Preserves All Data
  # ===========================================================================

  describe "5.7.3.1: backup/restore cycle preserves all data" do
    @tag :slow
    test "full backup and restore preserves all triples" do
      {store, path} = create_test_store(prefix: "ops_backup")
      backup_path = Path.join(System.tmp_dir!(), "backup_test_#{:rand.uniform(1_000_000)}")

      try do
        # Load test data
        loaded = load_test_data(store, 200)
        assert loaded == 200

        # Verify data before backup
        count_before = get_triple_count(store)
        assert count_before == 200

        # Create backup
        {:ok, metadata} = Backup.create(store, backup_path)
        assert metadata.path == backup_path
        assert metadata.file_count > 0
        assert metadata.size_bytes > 0

        # Close original store
        :ok = TripleStore.close(store)

        # Restore to new location
        restore_path = Path.join(System.tmp_dir!(), "restore_test_#{:rand.uniform(1_000_000)}")
        {:ok, restored_store} = Backup.restore(backup_path, restore_path)

        try do
          # Verify data after restore
          count_after = get_triple_count(restored_store)
          assert count_after == 200

          # Verify specific triple exists
          {:ok, specific} =
            TripleStore.query(
              restored_store,
              "SELECT ?v WHERE { <http://example.org/item100> <http://example.org/value> ?v }"
            )

          assert length(specific) == 1
        after
          TripleStore.close(restored_store)
          cleanup_test_path(restore_path)
        end
      after
        cleanup_test_path(path)
        cleanup_test_path(backup_path)
      end
    end

    @tag :slow
    test "backup preserves data with unique markers" do
      {store, path} = create_test_store(prefix: "ops_marker")
      backup_path = Path.join(System.tmp_dir!(), "marker_backup_#{:rand.uniform(1_000_000)}")

      try do
        # Load data with unique marker
        marker = "unique_#{:rand.uniform(999_999_999)}"

        {:ok, _} =
          TripleStore.update(store, """
            PREFIX ex: <http://example.org/>
            INSERT DATA {
              ex:marker ex:value "#{marker}" .
              ex:item1 ex:type ex:Thing .
              ex:item2 ex:type ex:Thing .
            }
          """)

        # Create backup
        {:ok, _} = Backup.create(store, backup_path)
        :ok = TripleStore.close(store)

        # Restore and verify marker
        restore_path = Path.join(System.tmp_dir!(), "marker_restore_#{:rand.uniform(1_000_000)}")
        {:ok, restored} = Backup.restore(backup_path, restore_path)

        try do
          {:ok, results} =
            TripleStore.query(
              restored,
              "SELECT ?v WHERE { <http://example.org/marker> <http://example.org/value> ?v }"
            )

          assert length(results) == 1
          # Verify we got some result back (the marker exists)
          result_value = results |> hd() |> Map.get("v")
          assert result_value != nil
        after
          TripleStore.close(restored)
          cleanup_test_path(restore_path)
        end
      after
        cleanup_test_path(path)
        cleanup_test_path(backup_path)
      end
    end

    @tag :slow
    test "backup rotation keeps only N most recent backups" do
      {store, path} = create_test_store(prefix: "ops_rotation")
      backup_dir = Path.join(System.tmp_dir!(), "rotation_test_#{:rand.uniform(1_000_000)}")
      File.mkdir_p!(backup_dir)

      try do
        load_test_data(store, 50)

        # Create multiple rotating backups with proper timing
        # Track successful backups to verify rotation is working
        successful_count =
          Enum.reduce(1..5, 0, fn _i, acc ->
            # rotate auto-generates unique timestamped paths
            case Backup.rotate(store, backup_dir, max_backups: 3) do
              {:ok, _} ->
                acc + 1

              {:error, reason} ->
                # Log but don't fail - timing issues can cause transient failures
                require Logger
                Logger.warning("Backup rotation attempt failed: #{inspect(reason)}")
                acc
            end
            # Delay > 1 second for unique timestamps
            |> tap(fn _ -> Process.sleep(1100) end)
          end)

        # At least some backups should have succeeded
        assert successful_count >= 3,
               "Expected at least 3 successful backups, got #{successful_count}"

        # List backups - rotation should limit to max_backups
        {:ok, backups} = Backup.list(backup_dir)

        # Should have exactly 3 backups if rotation worked correctly
        # Allow 2-3 for edge cases with timing
        assert length(backups) >= 2 and length(backups) <= 3,
               "Expected 2-3 backups after rotation, got #{length(backups)}"
      after
        cleanup_test_store(store, path)
        cleanup_test_path(backup_dir)
      end
    end

    @tag :slow
    test "backup creates restorable snapshot" do
      {store, path} = create_test_store(prefix: "ops_snapshot")
      backup_path = Path.join(System.tmp_dir!(), "snapshot_test_#{:rand.uniform(1_000_000)}")

      try do
        # Load initial data
        load_test_data(store, 100)

        # Add uniquely identifiable data
        {:ok, _} =
          TripleStore.update(store, """
            PREFIX ex: <http://example.org/>
            INSERT DATA {
              ex:snapshot_marker ex:created_at "2025-01-01" .
            }
          """)

        # Create full backup
        {:ok, meta} = Backup.create(store, backup_path)
        assert meta.backup_type == :full
        assert meta.file_count > 0

        :ok = TripleStore.close(store)
        Process.sleep(200)

        # Restore and verify
        restore_path =
          Path.join(System.tmp_dir!(), "snapshot_restore_#{:rand.uniform(1_000_000)}")

        {:ok, restored} = Backup.restore(backup_path, restore_path)

        try do
          # Should have all triples including marker
          count = get_triple_count(restored)
          # 100 + 1 marker
          assert count == 101

          # Verify marker exists
          {:ok, results} =
            TripleStore.query(
              restored,
              "SELECT ?d WHERE { <http://example.org/snapshot_marker> <http://example.org/created_at> ?d }"
            )

          assert length(results) == 1
        after
          TripleStore.close(restored)
          cleanup_test_path(restore_path)
        end
      after
        cleanup_test_path(path)
        cleanup_test_path(backup_path)
      end
    end
  end

  # ===========================================================================
  # 5.7.3.2: Telemetry Integration with Prometheus
  # ===========================================================================

  describe "5.7.3.2: telemetry integration with Prometheus" do
    @tag :slow
    test "Prometheus metrics are collected for queries" do
      {store, path} = create_test_store(prefix: "ops_prom")

      try do
        # Start Prometheus if not already started
        ensure_prometheus_started()

        load_test_data(store, 50)

        # Execute queries to generate telemetry
        for _i <- 1..5 do
          {:ok, _} = TripleStore.query(store, "SELECT * WHERE { ?s ?p ?o } LIMIT 10")
        end

        # Get Prometheus metrics
        metrics = Prometheus.format()

        # Should contain query metrics
        assert String.contains?(metrics, "triple_store_query_total")
        assert String.contains?(metrics, "triple_store_query_duration_seconds")
      after
        cleanup_test_store(store, path)
      end
    end

    test "Prometheus metrics are collected for inserts" do
      {store, path} = create_test_store(prefix: "ops_test")

      try do
        ensure_prometheus_started()

        # Execute inserts
        for i <- 1..3 do
          {:ok, _} =
            TripleStore.update(store, """
              PREFIX ex: <http://example.org/>
              INSERT DATA {
                ex:item#{i} ex:value #{i} .
              }
            """)
        end

        metrics = Prometheus.format()

        # Should contain insert metrics
        assert String.contains?(metrics, "triple_store_insert_total")
      after
        cleanup_test_store(store, path)
      end
    end

    test "Prometheus format is valid exposition format" do
      {store, path} = create_test_store(prefix: "ops_test")

      try do
        ensure_prometheus_started()

        load_test_data(store, 20)
        {:ok, _} = TripleStore.query(store, "SELECT * WHERE { ?s ?p ?o } LIMIT 5")

        metrics = Prometheus.format()

        # Verify format structure
        lines = String.split(metrics, "\n")

        # Should have HELP and TYPE lines
        help_lines = Enum.filter(lines, &String.starts_with?(&1, "# HELP"))
        type_lines = Enum.filter(lines, &String.starts_with?(&1, "# TYPE"))

        assert help_lines != []
        assert type_lines != []

        # Metric lines should have name and value
        metric_lines =
          Enum.filter(lines, fn line ->
            String.starts_with?(line, "triple_store_") and not String.starts_with?(line, "#")
          end)

        for line <- metric_lines do
          # Should have at least "metric_name value" format
          parts = String.split(line, " ")
          assert length(parts) >= 2, "Invalid metric line: #{line}"
        end
      after
        cleanup_test_store(store, path)
      end
    end

    test "Metrics GenServer collects and aggregates telemetry events" do
      {store, path} = create_test_store(prefix: "ops_test")

      try do
        # Start metrics collector with unique name
        metrics_name = :"test_metrics_#{:rand.uniform(1_000_000)}"
        {:ok, _pid} = Metrics.start_link(name: metrics_name)

        load_test_data(store, 30)

        # Execute operations
        for _i <- 1..3 do
          {:ok, _} = TripleStore.query(store, "SELECT * WHERE { ?s ?p ?o } LIMIT 10")
        end

        # Get aggregated stats
        stats = Metrics.get_all(name: metrics_name)

        assert stats.query.count >= 3
        assert stats.query.total_duration_ms >= 0

        GenServer.stop(metrics_name)
      after
        cleanup_test_store(store, path)
      end
    end

    test "telemetry events are emitted for all operations" do
      {store, path} = create_test_store(prefix: "ops_test")

      try do
        # Attach telemetry handler to capture events
        events_received = :ets.new(:test_events, [:set, :public])

        handler_id = "test_handler_#{:rand.uniform(1_000_000)}"

        # Listen for various telemetry events
        # Events are: [:triple_store, :subsystem, :operation, :phase]
        :telemetry.attach_many(
          handler_id,
          [
            [:triple_store, :sparql, :query, :stop],
            [:triple_store, :sparql, :update, :stop],
            [:triple_store, :insert, :stop],
            [:triple_store, :delete, :stop],
            [:triple_store, :load, :stop]
          ],
          fn event, _measurements, _metadata, _config ->
            :ets.insert(events_received, {event, true})
          end,
          nil
        )

        try do
          # Load data
          load_test_data(store, 10)

          # Query
          {:ok, _} = TripleStore.query(store, "SELECT * WHERE { ?s ?p ?o }")

          # Insert
          {:ok, _} =
            TripleStore.update(store, """
              PREFIX ex: <http://example.org/>
              INSERT DATA { ex:test ex:value "test" }
            """)

          # Delete
          {:ok, _} =
            TripleStore.update(store, """
              PREFIX ex: <http://example.org/>
              DELETE DATA { ex:test ex:value "test" }
            """)

          # Verify events were received
          # Query uses [:triple_store, :sparql, :query, :stop]
          assert :ets.lookup(events_received, [:triple_store, :sparql, :query, :stop]) != []
          # Update uses [:triple_store, :sparql, :update, :stop]
          assert :ets.lookup(events_received, [:triple_store, :sparql, :update, :stop]) != []
        after
          :telemetry.detach(handler_id)
          :ets.delete(events_received)
        end
      after
        cleanup_test_store(store, path)
      end
    end
  end

  # ===========================================================================
  # 5.7.3.3: Health Check Under Various Conditions
  # ===========================================================================

  describe "5.7.3.3: health check under various conditions" do
    test "store returns health status" do
      {store, path} = create_test_store(prefix: "ops_test")

      try do
        load_test_data(store, 50)

        {:ok, health} = Health.health(store)

        # Status may be :healthy or :degraded depending on cache processes
        assert health.status in [:healthy, :degraded]
        assert health.database_open == true
        assert health.dict_manager_alive == true
        assert health.triple_count == 50
      after
        cleanup_test_store(store, path)
      end
    end

    test "liveness check is fast and simple" do
      {store, path} = create_test_store(prefix: "ops_test")

      try do
        # Liveness should be very fast
        start = System.monotonic_time(:microsecond)
        result = Health.liveness(store)
        duration = System.monotonic_time(:microsecond) - start

        assert result == :ok
        # Should complete in under 10ms
        assert duration < 10_000, "Liveness check too slow: #{duration}Âµs"
      after
        cleanup_test_store(store, path)
      end
    end

    test "readiness check returns ready for healthy store" do
      {store, path} = create_test_store(prefix: "ops_test")

      try do
        load_test_data(store, 10)

        {:ok, status} = Health.readiness(store)
        assert status == :ready
      after
        cleanup_test_store(store, path)
      end
    end

    test "health check reports triple count accurately" do
      {store, path} = create_test_store(prefix: "ops_test")

      try do
        # Empty store
        {:ok, health1} = Health.health(store)
        assert health1.triple_count == 0

        # After loading
        load_test_data(store, 75)
        {:ok, health2} = Health.health(store)
        assert health2.triple_count == 75

        # Add additional unique triples (different prefix to avoid overwrites)
        additional_triples =
          for i <- 1..25 do
            {
              RDF.iri("http://example.org/extra#{i}"),
              RDF.iri("http://example.org/value"),
              RDF.literal(i)
            }
          end

        graph = RDF.Graph.new(additional_triples)
        {:ok, _} = TripleStore.load_graph(store, graph)

        {:ok, health3} = Health.health(store)
        # 75 + 25 = 100
        assert health3.triple_count == 100
      after
        cleanup_test_store(store, path)
      end
    end

    test "health check works during concurrent operations" do
      {store, path} = create_test_store(prefix: "ops_test")

      try do
        load_test_data(store, 100)

        # Start concurrent query tasks
        query_tasks =
          for _i <- 1..10 do
            Task.async(fn ->
              for _j <- 1..5 do
                TripleStore.query(store, "SELECT * WHERE { ?s ?p ?o } LIMIT 10")
              end
            end)
          end

        # Run health checks while queries are running
        health_results =
          for _i <- 1..5 do
            {:ok, health} = Health.health(store)
            health.status
          end

        # Wait for queries to complete
        Task.await_many(query_tasks, 30_000)

        # All health checks should succeed (may be :healthy or :degraded during load)
        assert Enum.all?(health_results, &(&1 in [:healthy, :degraded]))
      after
        cleanup_test_store(store, path)
      end
    end

    test "health check with include_all option provides extra details" do
      {store, path} = create_test_store(prefix: "ops_test")

      try do
        load_test_data(store, 50)

        {:ok, health} = Health.health(store, include_all: true)

        # Status may be :healthy or :degraded depending on cache processes
        assert health.status in [:healthy, :degraded]
        assert health.triple_count == 50

        # Should include extra details when include_all is true
        assert Map.has_key?(health, :database_open)
        assert Map.has_key?(health, :dict_manager_alive)
      after
        cleanup_test_store(store, path)
      end
    end

    test "health check returns index sizes" do
      {store, path} = create_test_store(prefix: "ops_test")

      try do
        load_test_data(store, 100)

        # get_index_sizes takes the db reference from the store
        sizes = Health.get_index_sizes(store.db)

        # Should have all index sizes
        assert Map.has_key?(sizes, :spo)
        assert Map.has_key?(sizes, :pos)
        assert Map.has_key?(sizes, :osp)

        # Sizes should be non-negative
        assert sizes.spo >= 0
        assert sizes.pos >= 0
        assert sizes.osp >= 0
      after
        cleanup_test_store(store, path)
      end
    end

    test "health check returns memory estimate" do
      {store, path} = create_test_store(prefix: "ops_test")

      try do
        load_test_data(store, 100)

        # estimate_memory takes a triple count, not a store
        triple_count = get_triple_count(store)
        memory = Health.estimate_memory(triple_count)

        assert Map.has_key?(memory, :beam_mb)
        assert Map.has_key?(memory, :estimated_data_mb)
        assert Map.has_key?(memory, :estimated_total_mb)

        # Values should be positive
        assert memory.beam_mb > 0
        assert memory.estimated_total_mb > 0
      after
        cleanup_test_store(store, path)
      end
    end
  end

  # ===========================================================================
  # 5.7.3.4: Graceful Shutdown and Restart
  # ===========================================================================

  describe "5.7.3.4: graceful shutdown and restart" do
    @tag :slow
    test "data persists after graceful close and reopen" do
      path = Path.join(System.tmp_dir!(), "shutdown_test_#{:rand.uniform(1_000_000)}")

      try do
        # Open and load data
        {:ok, store1} = TripleStore.open(path)
        load_test_data(store1, 100)

        # Verify data
        assert get_triple_count(store1) == 100

        # Graceful close
        :ok = TripleStore.close(store1)

        # Wait for RocksDB lock release - need sufficient time for Dict Manager cleanup
        Process.sleep(1000)

        # Force garbage collection to help release resources
        :erlang.garbage_collect()

        # Reopen (with retry for lock release)
        result = open_with_retry(path)
        assert match?({:ok, _}, result), "Failed to reopen store after close: #{inspect(result)}"
        {:ok, store2} = result

        try do
          # Verify data persisted
          assert get_triple_count(store2) == 100
        after
          TripleStore.close(store2)
        end
      after
        cleanup_test_path(path)
      end
    end

    test "pending operations complete before shutdown" do
      {store, path} = create_test_store(prefix: "ops_test")

      try do
        # Start multiple insert operations
        insert_tasks =
          for i <- 1..5 do
            Task.async(fn ->
              TripleStore.update(store, """
                PREFIX ex: <http://example.org/>
                INSERT DATA {
                  ex:batch#{i}_item1 ex:value #{i * 100 + 1} .
                  ex:batch#{i}_item2 ex:value #{i * 100 + 2} .
                }
              """)
            end)
          end

        # Wait for all inserts
        Task.await_many(insert_tasks, 30_000)

        # Close gracefully
        :ok = TripleStore.close(store)

        # Wait for RocksDB lock release
        Process.sleep(200)

        # Reopen and verify all data was persisted
        {:ok, store2} = open_with_retry(path)

        try do
          # 5 batches * 2 items = 10 triples
          assert get_triple_count(store2) == 10
        after
          TripleStore.close(store2)
        end
      after
        cleanup_test_path(path)
      end
    end

    test "second close returns already_closed error" do
      {store, path} = create_test_store(prefix: "ops_test")

      try do
        load_test_data(store, 10)
        :ok = TripleStore.close(store)

        # Second close should return error
        result = TripleStore.close(store)
        assert result == {:error, :already_closed}
      after
        cleanup_test_path(path)
      end
    end

    test "store can be reopened after close" do
      path = Path.join(System.tmp_dir!(), "reopen_test_#{:rand.uniform(1_000_000)}")

      try do
        # First session - load 50 items
        {:ok, store1} = TripleStore.open(path)
        load_test_data(store1, 50)
        :ok = TripleStore.close(store1)

        # Wait for lock release
        Process.sleep(300)

        # Second session - add 50 MORE unique items
        {:ok, store2} = open_with_retry(path)

        extra_triples =
          for i <- 1..50 do
            {
              RDF.iri("http://example.org/extra#{i}"),
              RDF.iri("http://example.org/value"),
              RDF.literal(i + 50)
            }
          end

        {:ok, _} = TripleStore.load_graph(store2, RDF.Graph.new(extra_triples))
        :ok = TripleStore.close(store2)

        # Wait for lock release
        Process.sleep(300)

        # Third session - verify cumulative data
        {:ok, store3} = open_with_retry(path)

        try do
          assert get_triple_count(store3) == 100
        after
          TripleStore.close(store3)
        end
      after
        cleanup_test_path(path)
      end
    end

    test "stats are available after reopen" do
      path = Path.join(System.tmp_dir!(), "stats_reopen_#{:rand.uniform(1_000_000)}")

      try do
        # First session
        {:ok, store1} = TripleStore.open(path)
        load_test_data(store1, 75)

        {:ok, stats1} = TripleStore.stats(store1)
        assert stats1.triple_count == 75

        :ok = TripleStore.close(store1)
        wait_for_lock_release()

        # Reopen and check stats
        {:ok, store2} = open_with_retry(path)

        try do
          {:ok, stats2} = TripleStore.stats(store2)
          assert stats2.triple_count == 75
        after
          TripleStore.close(store2)
        end
      after
        cleanup_test_path(path)
      end
    end

    test "health check works immediately after reopen" do
      path = Path.join(System.tmp_dir!(), "health_reopen_#{:rand.uniform(1_000_000)}")

      try do
        # First session
        {:ok, store1} = TripleStore.open(path)
        load_test_data(store1, 50)
        :ok = TripleStore.close(store1)
        Process.sleep(300)

        # Reopen
        {:ok, store2} = open_with_retry(path)

        try do
          # Health check should work immediately
          {:ok, health} = Health.health(store2)
          # Status may be :healthy or :degraded depending on cache processes
          assert health.status in [:healthy, :degraded]
          assert health.triple_count == 50
        after
          TripleStore.close(store2)
        end
      after
        cleanup_test_path(path)
      end
    end
  end
end
